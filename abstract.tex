\begin{abstract}
\vspace{-1cm}
% Cloud service providers offer rentable hardware and compute time to customers, allowing them to run arbitrary applications at large and dynamic scales.
% These providers have been working to offer new or more efficient features and services in competition for customers.
% Serverless computing has grown in popularity by orders of magnitude, and with it comes a continual call for enhancing performance to handle the increased load.
Cloud computing is comprised of a variety of services and abstractions to reduce the complexity of building and running applications.
% One of the latest, and most distinct of these, is \textit{serverless computing}.
% Instead of users managing scaling, virtual machines, operating system patches, containers, and more, a serverless application is orchestrated by the cloud provider and run only when needed.
Function as a Service is a unique abstraction amongst the many: user supplied code entirely managed by the cloud provider.
% This new abstraction has the opportunity to redefine cloud computing, a paradigm where application designer's only concern is their application, not complicated machine management and deployment.
Serverless control planes face unique challenges caused by the highly heterogeneous workloads predominant.
Users run machine learning inference, web services, multimedia analysis, and even scientific computing, to the tune of billions of invocations per day.
These, in turn, vary widely in resource usage, execution time, and frequency of invocation, which the control plane must handle efficiently.
It must also handle problems like cold start overheads neccessitated by executing invocations within isolated containers, and resource underutilization during idle periods.

This thesis addresses performance and resource management challenges by developing novel system designs and tailoring algorithms to handle these workloads.
% In this thesis I propose several enhancements, extensions, and modifications to serverless computing control planes.
% I describe several algorithms and policies that dramatically improve the resource utilization of such control planes.
% These tackle poor resource allocation and load scheduling at both individual server and cluster levels.
In it, we detail several algorithms that tackle poor resource allocation and load scheduling at both individual server and cluster levels.
The key finding of orchestration at both levels is the reliance on function characteristics in decision-making.
% The algorithms described here use take function characteristics .
% The latency of serverless invocations is reduced by 50\% as a result of these enhancements.
In addition, we describe a redesigned control plane, \sysname, that reduces latency spikes by 100x in existing open-source systems.
This is primarily accomplished by disaggregating scheduling decisions to avoid contention between distributed services of the control plane.
% My improved design reduces the latency of individual invocations by 10s-100s of ms, and allows for easy experimentation and accelerated research.
% Finally, I use this system to integrate GPU acceleration into serverless to showcase the computational flexibility and high degree of resource control found in serverless.
Finally, we leverage the high degree of resource control made possible by this new system to integrate GPU acceleration into the serverless ecosystem.
This uses a variety of novel mechanisms to minimize overhead despite limited device resources, boosting performance by several orders of magnitude over baseline solutions.
Altogether, the contributions of this thesis serverless improve latency by 75\% and cluster resource utilization by up to 20x.

\end{abstract}
