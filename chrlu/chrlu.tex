\chapter{Load- and Locality-Aware Load Balancing}
\label{chap:chrlu}

% While serverless computing provides more convenient abstractions for developing and deploying applications, the Function-as-a-Service (FaaS) programming model presents new resource management challenges for the FaaS provider. 
In this chapter, we investigate load-balancing policies for serverless clusters and find that the locality vs. load tradeoff is crucial and presents a large design space.
Locality, i.e., running repeated invocations of a function on the same server, is a key determinant of performance because it increases warm-starts and reduces cold start overheads.
Many functions are too popular and running all their invocations on one worker will overload it, requiring us to sacrifice locality and spread their invocations across the cluster.
We find that the locality vs. load tradeoff is crucial and presents a large design space. 

We enhance consistent hashing and bring it to FaaS, developing CH-RLU: Consistent Hashing with Random Load Updates, a simple, practical load-balancing policy which provides more than $2\times$ reduction in function latency. 
Our policy deals with highly heterogeneous, skewed, and bursty function workloads, and is a drop-in replacement for OpenWhisk's existing load-balancer.
We leverage techniques from caching such as SHARDS for popularity detection, and develop a new approach that places functions based on a tradeoff between function locality, cluster load, and randomness. 


\input{chrlu/bg.tex}

\input{chrlu/design.prateek.tex}

\input{chrlu/implementation.tex}

\input{chrlu/eval.tex}

\input{chrlu/related.tex}

%~\cite{lbfaas-hpdc2022}

In this chapter we have explored the tradeoff between locality and load for serverless functions. 
Our CH-RLU policy can tackle the challenges of function heterogeneity, workload skew, bursty workloads, and stale loads.
We enhance consistent hashing to yield a simple and practical load-balancing policy. 
Empirical evaluation shows substantial improvements in function latency (by more than $2\times$) compared to OpenWhisk's load balancing strategy.


\begin{comment}
\begin{figure}
  \includegraphics[width=.9\columnwidth]{./figures/consistent-hashing.png}
  \caption{Consistent hashing ring featuring function forwarding~\cite{lbfaas-hpdc2022}.}
  \label{fig:ch-rlu}
\end{figure}

In my work just accepted to HPDC~\cite{lbfaas-hpdc2022}, we take a different approach to load and locality balancing.
% Some functions are more \textit{popular} than others, and therefore will take up more system resources.
Previous work~\cite{shahrad2020serverless} revealed that a few functions make up the lion's share of invocations in FaaS systems.
Per Figure~\ref{fig:serverless-invocations} over 99\% of invocations are from just 19\% of functions, and load balancers need to take this pattern into account.
To start our balancing policy we use consistent hashing to always route a function to a home worker, favoring locality especially for those rarely invoked functions.
In the event a home worker is overloaded, we want to conditionally migrate work to other workers in an affinity-aware manner.
This load based migration locality is achieved by \textit{pushing} work around the has ring as shown in Figure~\ref{fig:ch-rlu}.
As a server's load increases, invocations are randomly pushed around the ring with popular functions being more likely to be forwarded.
This spreads work around preventing load imbalance, maintains locality for functions, and avoids latency increases from high CPU load on any individual worker.
\end{comment}