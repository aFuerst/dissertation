%Priority and Locality aware Load-Balancing For Serverless Clusters
%FaaSting: Better Serverless Performance with Delay-Tolerant Functions and Service Differentiation

%
%Old conference paper abstract
%
% While serverless computing provides more convenient abstractions for developing and deploying applications, the Function-as-a-Service (FaaS) programming model presents new resource management challenges for the FaaS provider. 
% In this paper, we investigate load-balancing policies for serverless clusters.
% Locality, i.e., running repeated invocations of a function on the same server, is a key determinant of performance because it increases warm-starts and reduces cold-start overheads. 
% We find that the locality vs. load tradeoff is crucial and presents a large design space. 

% We enhance consistent hashing for FaaS, and develop CH-RLU: Consistent Hashing with Random Load Updates, a simple practical load-balancing policy which provides more than $2\times$ reduction in function latency. 
% Our policy deals with highly heterogeneous, skewed, and bursty function workloads, and is a drop-in replacement for OpenWhisk's existing load-balancer.
% We leverage techniques from caching such as SHARDS for popularity detection, and develop a new approach that places functions based on a tradeoff between locality, load, and randomness. 

%
% First abstract draft, for journal paper
%
%Context
% Function-as-a-Service (FaaS)
An ever-increasing range of applications and workflows now rely on Functions as a Service (FaaS).
As the adoption of serverless computing keeps growing, cloud providers must increase the efficiency in managing the resources of the clusters where these services run.
However, the heterogeneity, scale, and different latency tolerances of functions makes scheduling and load-balancing challenging. 

In this paper, we show it is feasible and effective to prioritize functions by their latency tolerances, to provide differentiated quality-of-service (QoS).
We extend Consistent Hashing with priority-, locality-, and server load-awareness as key principles, and introduce a new load-balancing algorithm, $k$-CH-RLU.
$k$-CH-RLU supports $k$ priority levels, dynamically assigns more resources to higher priority functions, and mitigates workload bursts. 
We implement and evaluate $k$-CH-RLU in OpenWhisk;
experiments show that our algorithm can improve latency of all functions by up to $5\times$ compared to OpenWhisk.
Our function prioritization can also reduce the total resources required:
We can reduce latency of high-priority functions by $3\times$ even with $25\%$ fewer servers. 

%
%Some un-used text from conference paper:
%
% and uses the newly-found equivalence between FaaS and caching~\cite{faascache-asplos21} 
% Prior work has looked at optimizing FaaS performance on a \emph{single} server. 
% We find that the principles of locality and avoiding cold-starts continue to remain key determinants of application and system performance even in distributed setups. 
% However, translating these lessons to a cluster of servers presents us with new challenges.
% We develop a new consistent hashing based technique that takes into account function cold starts, and staleness of server loads.
% Our technique can mitigate severe workload spikes and extreme workload heterogeneity.
% Implementation and evaluation in OpenWhisk shows an average latency reduction of 2x over competitive policies.



%%% Local Variables:
%%% mode: latex
%%% TeX-master: "paper"
%%% End:
